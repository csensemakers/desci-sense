{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from desci_sense.configs import default_init_parser_config\n",
    "from desci_sense.shared_functions.dataloaders import scrape_post, convert_text_to_ref_post\n",
    "from desci_sense.shared_functions.parsers.firebase_api_parser import FirebaseAPIParser, PromptCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = default_init_parser_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-19 17:14:06.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36mset_md_extract_method\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mSetting metadata extraction method to none...\u001b[0m\n",
      "\u001b[32m2024-02-19 17:14:06.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mLoading parser model (type=mistralai/mistral-7b-instruct)...\u001b[0m\n",
      "/Users/ronentamari/anaconda3/envs/asensebot/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "\u001b[32m2024-02-19 17:14:07.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36mset_kw_md_extract_method\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mSetting keywords metadata extraction method to citoid...\u001b[0m\n",
      "\u001b[32m2024-02-19 17:14:07.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36minit_keyword_extraction_chain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mLoading keyword model (type=mistralai/mistral-7b-instruct)...\u001b[0m\n",
      "\u001b[32m2024-02-19 17:14:07.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mLoading ontology...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "parser = FirebaseAPIParser(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-19 17:14:08.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdesci_sense.shared_functions.parsers.firebase_api_parser\u001b[0m:\u001b[36mset_md_extract_method\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mSetting metadata extraction method to citoid...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "parser.set_md_extract_method(\"citoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_POST_TEXT_W_REF = \"\"\"\n",
    "I really liked this paper!\n",
    "https://arxiv.org/abs/2402.04607\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = convert_text_to_ref_post(TEST_POST_TEXT_W_REF)\n",
    "combined = parser.process_ref_post_parallel(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['self-citations', 'google-scholar', 'citation-fraud', 'scientific-evaluation']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[\"keywords\"][\"answer\"][\"valid_keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_proc = parser.post_process_result(**combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ns1: <https://pcp-on-web.de/ontology/0.2/index-en.html#> .\n",
      "@prefix ns2: <https://sense-nets.xyz/> .\n",
      "@prefix ns3: <http://purl.org/spar/cito/> .\n",
      "\n",
      "<http://purl.org/nanopub/temp/mynanopub#assertion> ns3:agreesWith <https://arxiv.org/abs/2402.04607> ;\n",
      "    ns1:hasKeyword \"citation-fraud\",\n",
      "        \"google-scholar\",\n",
      "        \"scientific-evaluation\",\n",
      "        \"self-citations\" ;\n",
      "    ns2:readingStatus <https://arxiv.org/abs/2402.04607> .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(post_proc.model_dump()[\"semantics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "presult = parser.process_text_parallel(TEST_POST_TEXT_W_REF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ns1: <https://pcp-on-web.de/ontology/0.2/index-en.html#> .\n",
      "@prefix ns2: <https://sense-nets.xyz/> .\n",
      "\n",
      "<http://purl.org/nanopub/temp/mynanopub#assertion> ns1:hasKeyword \"academic-integrity\",\n",
      "        \"citation-fraud\",\n",
      "        \"evaluation\",\n",
      "        \"google-scholar\",\n",
      "        \"preprint\",\n",
      "        \"scientists\" ;\n",
      "    ns2:readingStatus <https://arxiv.org/abs/2402.04607> .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(presult.semantics.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwords = parser.extract_post_topics_w_metadata(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SelfCitations',\n",
       " 'CitationFraud',\n",
       " 'CitationCartels',\n",
       " 'GoogleScholar',\n",
       " 'CitationManipulation',\n",
       " 'ScientificEvaluation']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwords[\"answer\"][\"valid_keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = parser.process_ref_post(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = parser.prompt_case_dict[PromptCase.SINGLE_REF][\"chain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], template='{input}')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x28f0f5410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x28fcbb850>, model_name='mistralai/mistral-7b-instruct', temperature=0.6, openai_api_key='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', openai_api_base='https://openrouter.ai/api/v1', openai_proxy='')\n",
       "| TagTypeParser(allowed_tags=['endorses', 'disagrees', 'agrees', 'watching', 'reading', 'listening', 'default', 'review', 'recommendation', 'question', 'quote', 'discussion', 'event', 'job', 'announce'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['kw_input'], template='{kw_input}')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x28fcc3850>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x28fcd2cd0>, model_name='mistralai/mistral-7b-instruct', temperature=0.6, openai_api_key='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', openai_api_base='https://openrouter.ai/api/v1', openai_proxy='')\n",
       "| KeywordParser(max_keywords=6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_chain = parser.kw_extraction[\"chain\"]\n",
    "kw_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = convert_text_to_ref_post(TEST_POST_TEXT_W_REF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = parser.process_ref_post_st(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_prompt = result[\"full_prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_result = parser.extract_post_topics_w_metadata(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_prompt = kw_result[\"full_prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_chain = RunnableParallel(semantics=chain, keywords=kw_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_res = map_chain.invoke({\"kw_input\": kw_prompt, \"input\": parser_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': '[Reasoning Steps]\\n\\n[System error: failed to extract reasoning steps since the generated output was in an invalid format]\\n\\n[Candidate Tags]\\n\\n[System error: failed to extract candidate tags since the generated output was in an invalid format.]',\n",
       " 'final_answer': '1. #citation-fraud\\n2. #Google-Scholar\\n3. #scientific-evaluation\\n4. #inflation\\n5. #manipulability\\n6. #citation-cartels',\n",
       " 'valid_keywords': ['citation-cartels',\n",
       "  'manipulability',\n",
       "  'scientific-evaluation',\n",
       "  'Google-Scholar',\n",
       "  'citation-fraud',\n",
       "  'inflation']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_res[\"keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_chain = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model\n",
    "poem_chain = (\n",
    "    ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\") | model\n",
    ")\n",
    "\n",
    "map_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21 s ± 148 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "map_chain.invoke({\"topic\": \"bear\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 s ± 240 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "joke_chain.invoke({\"topic\": \"bear\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 s ± 302 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "poem_chain.invoke({\"topic\": \"bear\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensebot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
